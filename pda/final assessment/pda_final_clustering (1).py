# -*- coding: utf-8 -*-
"""pda_final_clustering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CqLOjxNYB0DYrFSUgIthXKoUHuTeHbeL
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler,LabelEncoder
from sklearn.metrics import silhouette_score

df=pd.read_csv('https://raw.githubusercontent.com/Deepsphere-AI/LVA-Batch5-Assessment/main/customer_segmentation.csv')

df.info()

df.head()

df.describe()

df.duplicated().sum()

df.isnull().sum()

m_value=df['Income'].median()
df['Income']=df['Income'].fillna(m_value)
print(df.isnull().sum())

num_col=[x for x in df.select_dtypes(include=['float64','int64']).columns]
print(num_col)
print('-------')
cat_col=[x for x in df.select_dtypes(include='object').columns]
print(cat_col)

#eda
for n in num_col:
  plt.figure(figsize=(10,5))
  sns.histplot(df[n])
  plt.xlabel(n)
  plt.ylabel('frequency')
  plt.title(f'histogram of {n}')
  plt.show()

for c in cat_col:
  plt.figure(figsize=(10,5))
  df[c].value_counts().plot(kind='bar')
  plt.xlabel(n)
  plt.ylabel('frequency')
  plt.title(f'bar of {c}')
  plt.show()

#scatter plot
#bivarient
for i in range(len(num_col)):
  for j in range(i+1,len(num_col)):
    plt.figure(figsize=(10,5))
    sns.scatterplot(data=df,x=num_col[i],y=num_col[j])
    plt.xlabel(num_col[i])
    plt.ylabel(num_col[j])
    plt.title(f'sactter plot of {num_col[i]} and {num_col[j]}')
    plt.show()

#multivarient analysis analysis
corr_mat=df[num_col].corr()
print(corr_mat)
plt.figure(figsize=(10,5))
sns.heatmap(corr_mat,annot=True,cmap='coolwarm')
plt.title('heat map of corelation matrix')
plt.show()

needed_col=['Income','Kidhome','Recency','NumDealsPurchases','NumWebVisitsMonth','NumStorePurchases','Complain','Z_Revenue']

le=LabelEncoder()
for i in cat_col:
  df[i]=le.fit_transform(df[i])

#corr matrix
corr_mat=df.corr()
print(corr_mat)
plt.figure(figsize=(10,5))
sns.heatmap(corr_mat,annot=True,cmap='coolwarm')
plt.title('heat map of corelation matrix after encoding')
plt.show()

drop_df=df[needed_col]

scaler=MinMaxScaler()
drop_df=pd.DataFrame(scaler.fit_transform(drop_df),columns=drop_df.columns)

drop_df.head()

#elbow method
wcss=[]
for i in range(1,11):
  model=KMeans(n_clusters=i,init='k-means++',random_state=42)
  model.fit(drop_df)
  wcss.append(model.inertia_)
plt.plot(range(1,11),wcss,marker='o')
plt.grid=True
plt.show()

#kmeans taking k sa 3 as per elbow diagram
kmeans=KMeans(n_clusters=3)
kmeans.fit(drop_df)
labels=kmeans.labels_
drop_df['labels']=labels
centers = kmeans.cluster_centers_

#visualisation
cluster_name=['cluster1','cluster2']
plt.figure(figsize=(10,6))
plt.scatter(drop_df.iloc[:,0],drop_df.iloc[:,1],c=labels,cmap='viridis',s=50,alpha=0.5)
for i , clus in enumerate(cluster_name):
  plt.scatter([],[],label=clus,c=plt.cm.viridis(i/len(cluster_name)-1),alpha=0.5)
plt.legend()
plt.show()

ss=silhouette_score(drop_df,kmeans.labels_)
print(f'silhouette_score {ss}')

