# -*- coding: utf-8 -*-
"""pda_final_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rgK4d8QqK9OreqMJxa9CtYLzMO98Pc2y
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler,LabelEncoder
from sklearn.metrics import accuracy_score,recall_score,f1_score,precision_score,confusion_matrix,classification_report

df=pd.read_csv('https://raw.githubusercontent.com/Deepsphere-AI/LVA-Batch5-Assessment/main/penguins_classification.csv')

df.info()

df.duplicated().sum()

df.isnull().sum()

df.head()

df.describe()

# bill_depth_mm is float so median filoing
m_value=df['bill_depth_mm'].median()
df['bill_depth_mm']=df['bill_depth_mm'].fillna(m_value)
print(df.isnull().sum())

num_col=[x for x in df.select_dtypes(include=['float64','int64']).columns]
print(num_col)
print('-------')
cat_col=[x for x in df.select_dtypes(include='object').columns]
print(cat_col)

#eda
for n in num_col:
  plt.figure(figsize=(10,5))
  sns.histplot(df[n])
  plt.xlabel(n)
  plt.ylabel('frequency')
  plt.title(f'histogram of {n}')
  plt.show()

for c in cat_col:
  plt.figure(figsize=(10,5))
  df[c].value_counts().plot(kind='bar')
  plt.xlabel(n)
  plt.ylabel('frequency')
  plt.title(f'bar of {c}')
  plt.show()

#bivarient
for i in range(len(num_col)):
  for j in range(i+1,len(num_col)):
    plt.figure(figsize=(10,5))
    sns.scatterplot(data=df,x=num_col[i],y=num_col[j])
    plt.xlabel(num_col[i])
    plt.ylabel(num_col[j])
    plt.title(f'sactter plot of {num_col[i]} and {num_col[j]}')
    plt.show()

#multivarient analysis analysis
corr_mat=df[num_col].corr()
print(corr_mat)
plt.figure(figsize=(10,5))
sns.heatmap(corr_mat,annot=True,cmap='coolwarm')
plt.title('heat map of corelation matrix')
plt.show()

#encoding
le=LabelEncoder()
for i in cat_col:
  df[i]=le.fit_transform(df[i])

df.info()

#corr matrix
corr_mat=df.corr()
print(corr_mat)
plt.figure(figsize=(10,5))
sns.heatmap(corr_mat,annot=True,cmap='coolwarm')
plt.title('heat map of corelation matrix')
plt.show()

# X_ne=df.drop(labels=['species','year'],axis=1)
X_ne=df.drop(labels=['species'],axis=1)
Y_ne=df['species']
x_train_ne,x_test_ne,y_train_ne,y_test_ne=train_test_split(X_ne,Y_ne,test_size=0.3)

#random forest model
rf=RandomForestClassifier(random_state=42,n_estimators=50)
rf.fit(x_train_ne,y_train_ne)
y_pred=rf.predict(x_test_ne)

#evaluation of model
print(y_pred)
print('-----------------')
print(accuracy_score(y_test_ne,y_pred))
print(recall_score(y_test_ne,y_pred))
print(precision_score(y_test_ne,y_pred))
print(f1_score(y_test_ne,y_pred))
print(confusion_matrix(y_test_ne,y_pred))
print(classification_report(y_test_ne,y_pred))

'''
as the number of data pointsa re less the model is over fitted and it is also because of low corelation between all the columns.'''

